from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy import select
from typing import Optional, List
from datetime import datetime, timedelta
import json
import time

from app.core.database import get_db_sync
from app.models.sqlite import (
    Device,
    PerformanceMetric,
    SoftwareBenchmark,
    AIAnalysisReport,
    PositionStandard,
)
from app.schemas.performance import AIAnalysisRequest, AIAnalysisResponse
from app.services.ai_analysis_service import AIAnalysisService

router = APIRouter(prefix="/ai", tags=["AI Analysis"])


def device_to_info(device: Device) -> dict:
    """è½¬æ¢è®¾å¤‡ä¿¡æ¯ä¸ºå­—å…¸"""
    return {
        "id": device.id,
        "device_name": device.device_name,
        "cpu_model": device.cpu_model,
        "cpu_cores": device.cpu_cores,
        "cpu_threads": device.cpu_threads,
        "gpu_model": device.gpu_model,
        "gpu_vram_mb": device.gpu_vram_mb,
        "ram_total_gb": device.ram_total_gb,
        "disk_type": device.disk_type,
        "disk_capacity_tb": device.disk_capacity_tb,
    }


@router.post("/analyze", response_model=AIAnalysisResponse)
def analyze_general(
    request: AIAnalysisRequest,
    db: Session = Depends(get_db_sync),
):
    """
    é€šç”¨ AI åˆ†ææ¥å£ - æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢
    """
    analysis_service = AIAnalysisService()

    # è·å–ç”¨æˆ·æŸ¥è¯¢
    query = request.query

    if not query:
        return {"status": "error", "summary": "è¯·æä¾›æŸ¥è¯¢å†…å®¹"}

    # å…ˆå°è¯•ç›´æ¥æŸ¥è¯¢è®¾å¤‡åˆ—è¡¨ï¼ˆç”¨äº"åˆ—å‡ºè®¾å¤‡"ç­‰åœºæ™¯ï¼‰
    if any(
        keyword in query
        for keyword in ["åˆ—å‡º", "åˆ—è¡¨", "æ˜¾ç¤ºè®¾å¤‡", "æ‰€æœ‰è®¾å¤‡", "è®¾å¤‡åˆ—è¡¨", "æŸ¥çœ‹è®¾å¤‡"]
    ):
        try:
            devices_result = db.execute(select(Device).limit(50))
            devices = devices_result.scalars().all()

            if devices:
                device_list = []
                for d in devices:
                    status = "ğŸŸ¢ åœ¨çº¿" if d.status == "online" else "ğŸ”´ ç¦»çº¿"
                    device_list.append(
                        f"â€¢ {d.device_name} - {status}\n  CPU: {d.cpu_model or 'æœªçŸ¥'}\n  GPU: {d.gpu_model or 'æœªçŸ¥'}"
                    )

                return {
                    "status": "completed",
                    "summary": "ğŸ“Š è®¾å¤‡åˆ—è¡¨ï¼š\n\n" + "\n\n".join(device_list),
                    "device_id": request.device_id or "",
                    "analysis_type": request.analysis_type or "general",
                    "title": "è®¾å¤‡åˆ—è¡¨æŸ¥è¯¢",
                }
        except Exception as e:
            pass  # å¦‚æœå¤±è´¥ï¼Œç»§ç»­èµ°AIåˆ†æ

    # è·å–è®¾å¤‡ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº† device_idï¼‰
    device_info = None
    if request.device_id:
        device_result = db.execute(select(Device).where(Device.id == request.device_id))
        device = device_result.scalar_one_or_none()
        if device:
            device_info = device_to_info(device)

    try:
        # æ„å»ºæç¤ºè¯ï¼Œè®© AI å›ç­”é—®é¢˜æ—¶ä½¿ç”¨ä¸­æ–‡å¹¶ä¿æŒæ¢è¡Œ
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¡¬ä»¶æ€§èƒ½åˆ†æåŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

{"è®¾å¤‡ä¿¡æ¯ï¼š" + str(device_info) if device_info else ""}

é‡è¦è¦æ±‚ï¼š
1. ä½¿ç”¨æ¢è¡Œç¬¦(\\n)æ¥åˆ†éš”ä¸åŒå†…å®¹
2. ä¸è¦ä½¿ç”¨è¡¨æ ¼æ ¼å¼ï¼Œä½¿ç”¨åˆ—è¡¨å’Œé¡¹ç›®ç¬¦å·
3. ä¿æŒç®€æ´æ¸…æ™°çš„æ ¼å¼"""

        result = analysis_service.llm.chat(
            message=prompt,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¡¬ä»¶æ€§èƒ½åˆ†æåŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä½¿ç”¨æ¢è¡Œç¬¦æ¥åˆ†éš”å†…å®¹ï¼Œä¸è¦ä½¿ç”¨è¡¨æ ¼ã€‚",
            temperature=0.7,
            max_tokens=1500,
        )

        summary = result.get("content", "")

        return {
            "status": "completed",
            "summary": summary,
            "device_id": request.device_id or "",
            "analysis_type": request.analysis_type or "general",
            "title": f"AI åˆ†æ - {query[:30]}",
        }

    except Exception as e:
        return {"status": "error", "summary": f"åˆ†æå¤±è´¥ï¼š{str(e)}"}


@router.post("/analyze/metrics", response_model=AIAnalysisResponse)
def analyze_realtime_metrics(
    device_id: str,
    seconds: int = Query(60, ge=10, le=3600, description="åˆ†ææœ€è¿‘Nç§’çš„æ•°æ®"),
    db: Session = Depends(get_db_sync),
):
    """
    åˆ†æè®¾å¤‡å®æ—¶æ€§èƒ½æŒ‡æ ‡
    """
    # è·å–è®¾å¤‡ä¿¡æ¯
    device_result = db.execute(select(Device).where(Device.id == device_id))
    device = device_result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")

    # è·å–æœ€è¿‘ N ç§’çš„æ€§èƒ½æŒ‡æ ‡
    since = datetime.utcnow() - timedelta(seconds=seconds)
    metrics_result = db.execute(
        select(PerformanceMetric)
        .where(PerformanceMetric.device_id == device_id)
        .where(PerformanceMetric.timestamp >= since)
        .order_by(PerformanceMetric.timestamp.asc())
    )
    metrics = metrics_result.scalars().all()

    if not metrics:
        raise HTTPException(
            status_code=404, detail="No metrics found for the specified time range"
        )

    # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
    metrics_data = []
    for m in metrics:
        metrics_data.append(
            {
                "timestamp": m.timestamp.isoformat() if m.timestamp else None,
                "cpu_percent": m.cpu_percent,
                "gpu_percent": m.gpu_percent,
                "memory_percent": m.memory_percent,
                "cpu_temperature": m.cpu_temperature,
                "gpu_temperature": m.gpu_temperature,
            }
        )

    # è°ƒç”¨ AI åˆ†ææœåŠ¡
    analysis_service = AIAnalysisService()
    device_info = device_to_info(device)
    result = analysis_service.analyze_realtime_metrics(device_info, metrics_data)

    # ä¿å­˜åˆ†ææŠ¥å‘Š
    if result.get("status") == "completed":
        report = AIAnalysisReport(
            device_id=device_id,
            analysis_type="realtime_metrics",
            title=f"å®æ—¶æ€§èƒ½åˆ†æ - {device.device_name}",
            summary=result.get("summary", ""),
            details=json.dumps(
                {
                    "metrics_summary": result.get("metrics_summary"),
                    "issues": result.get("issues"),
                },
                ensure_ascii=False,
            ),
            status="completed",
            model_used=result.get("model"),
            analysis_duration_ms=int(
                result.get("usage", {}).get("total_tokens", 0) * 10
            ),  # ä¼°ç®—
        )
        db.add(report)
        db.commit()
        db.refresh(report)

        return {
            "report_id": report.id,
            "status": result.get("status"),
            "summary": result.get("summary"),
            "conclusions": result.get("summary"),
            "recommendations": "\n".join(result.get("issues", [])),
            "details": result.get("metrics_summary"),
        }

    raise HTTPException(
        status_code=500, detail=result.get("message", "Analysis failed")
    )


@router.post("/analyze/benchmark/{benchmark_id}", response_model=AIAnalysisResponse)
def analyze_benchmark_result(benchmark_id: str, db: Session = Depends(get_db_sync)):
    """
    åˆ†æåŸºå‡†æµ‹è¯•ç»“æœ
    """
    # è·å–åŸºå‡†æµ‹è¯•è®°å½•
    benchmark_result = db.execute(
        select(SoftwareBenchmark).where(SoftwareBenchmark.id == benchmark_id)
    )
    benchmark = benchmark_result.scalar_one_or_none()
    if not benchmark:
        raise HTTPException(status_code=404, detail="Benchmark not found")

    # è·å–è®¾å¤‡ä¿¡æ¯
    device_result = db.execute(select(Device).where(Device.id == benchmark.device_id))
    device = device_result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")

    # è°ƒç”¨ AI åˆ†ææœåŠ¡
    analysis_service = AIAnalysisService()
    device_info = device_to_info(device)
    benchmark_data = {
        "id": benchmark.id,
        "software_code": benchmark.software_code,
        "benchmark_type": benchmark.benchmark_type,
        "test_scene": benchmark.test_scene,
        "score": benchmark.score,
        "score_cpu": benchmark.score_cpu,
        "score_gpu": benchmark.score_gpu,
        "score_memory": benchmark.score_memory,
        "score_disk": benchmark.score_disk,
        "avg_fps": benchmark.avg_fps,
        "render_time_seconds": benchmark.render_time_seconds,
        "peak_cpu_percent": benchmark.peak_cpu_percent,
        "peak_gpu_percent": benchmark.peak_gpu_percent,
        "peak_memory_mb": benchmark.peak_memory_mb,
        "status": benchmark.status,
    }

    result = analysis_service.analyze_benchmark(device_info, benchmark_data)

    # ä¿å­˜åˆ†ææŠ¥å‘Š
    if result.get("status") == "completed":
        report = AIAnalysisReport(
            device_id=benchmark.device_id,
            analysis_type="benchmark",
            title=f"åŸºå‡†æµ‹è¯•åˆ†æ - {benchmark.software_code}",
            summary=result.get("analysis", ""),
            details=json.dumps(
                {
                    "benchmark_id": benchmark_id,
                    "bottleneck_type": result.get("bottleneck_type"),
                    "upgrade_suggestion": result.get("upgrade_suggestion"),
                    "estimated_improvement": result.get("estimated_improvement"),
                },
                ensure_ascii=False,
            ),
            conclusions=result.get("analysis", ""),
            recommendations=result.get("upgrade_suggestion", ""),
            related_benchmarks=json.dumps([benchmark_id]),
            status="completed",
            model_used=result.get("model"),
        )
        db.add(report)
        db.commit()
        db.refresh(report)

        # æ›´æ–°åŸºå‡†æµ‹è¯•è®°å½•çš„ç“¶é¢ˆåˆ†æ
        benchmark.bottleneck_type = result.get("bottleneck_type")
        benchmark.bottleneck_detail = result.get("analysis", "")
        benchmark.upgrade_suggestion = result.get("upgrade_suggestion", "")
        db.commit()

        return {
            "report_id": report.id,
            "status": result.get("status"),
            "summary": result.get("analysis"),
            "conclusions": result.get("analysis"),
            "recommendations": result.get("upgrade_suggestion"),
            "details": {
                "bottleneck_type": result.get("bottleneck_type"),
                "estimated_improvement": result.get("estimated_improvement"),
            },
        }

    raise HTTPException(
        status_code=500, detail=result.get("message", "Analysis failed")
    )


@router.post("/analyze/upgrade", response_model=AIAnalysisResponse)
def analyze_upgrade_recommendation(
    device_id: str,
    position_id: Optional[str] = Query(None, description="å²—ä½IDï¼Œç”¨äºåŒ¹é…å²—ä½éœ€æ±‚"),
    db: Session = Depends(get_db_sync),
):
    """
    ç”Ÿæˆç¡¬ä»¶å‡çº§å»ºè®®
    """
    # è·å–è®¾å¤‡ä¿¡æ¯
    device_result = db.execute(select(Device).where(Device.id == device_id))
    device = device_result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")

    # è·å–æœ€è¿‘çš„åŸºå‡†æµ‹è¯•ç»“æœ
    benchmarks_result = db.execute(
        select(SoftwareBenchmark)
        .where(SoftwareBenchmark.device_id == device_id)
        .order_by(SoftwareBenchmark.timestamp.desc())
        .limit(10)
    )
    benchmarks = benchmarks_result.scalars().all()

    benchmarks_data = []
    for b in benchmarks:
        benchmarks_data.append(
            {
                "id": b.id,
                "software_code": b.software_code,
                "benchmark_type": b.benchmark_type,
                "score": b.score,
                "status": b.status,
                "avg_cpu_percent": b.avg_cpu_percent,
                "avg_gpu_percent": b.avg_gpu_percent,
            }
        )

    # è·å–å²—ä½éœ€æ±‚ï¼ˆå¦‚æœæœ‰ï¼‰
    position_requirements = None
    if position_id:
        position_result = db.execute(
            select(PositionStandard).where(PositionStandard.id == position_id)
        )
        position = position_result.scalar_one_or_none()
        if position:
            position_requirements = {
                "position_name": position.position_name,
                "cpu_min_cores": position.cpu_min_cores,
                "cpu_min_threads": position.cpu_min_threads,
                "ram_min_gb": position.ram_min_gb,
                "gpu_min_vram_mb": position.gpu_min_vram_mb,
                "viewport_fps_min": position.viewport_fps_min,
                "render_time_max_seconds": position.render_time_max_seconds,
            }

    # è°ƒç”¨ AI åˆ†ææœåŠ¡
    analysis_service = AIAnalysisService()
    device_info = device_to_info(device)
    result = analysis_service.generate_upgrade_recommendation(
        device_info, benchmarks_data, position_requirements
    )

    # ä¿å­˜åˆ†ææŠ¥å‘Š
    if result.get("status") == "completed":
        report = AIAnalysisReport(
            device_id=device_id,
            analysis_type="upgrade_recommendation",
            title=f"ç¡¬ä»¶å‡çº§å»ºè®® - {device.device_name}",
            summary=result.get("recommendation", ""),
            details=json.dumps(
                {
                    "benchmarks_count": len(benchmarks_data),
                    "position_requirements": position_requirements,
                },
                ensure_ascii=False,
            ),
            conclusions=result.get("recommendation", ""),
            recommendations=result.get("recommendation", ""),
            related_benchmarks=json.dumps([b.id for b in benchmarks]),
            status="completed",
            model_used=result.get("model"),
        )
        db.add(report)
        db.commit()
        db.refresh(report)

        return {
            "report_id": report.id,
            "status": result.get("status"),
            "summary": result.get("recommendation"),
            "conclusions": result.get("recommendation"),
            "recommendations": result.get("recommendation"),
            "details": {
                "benchmarks_analyzed": len(benchmarks_data),
                "position_requirements_matched": position_id is not None,
            },
        }

    raise HTTPException(
        status_code=500, detail=result.get("message", "Analysis failed")
    )


@router.post("/analyze/trend", response_model=AIAnalysisResponse)
def analyze_performance_trend(
    device_id: str,
    hours: int = Query(72, ge=24, le=720, description="åˆ†ææœ€è¿‘Nå°æ—¶çš„æ•°æ®"),
    db: Session = Depends(get_db_sync),
):
    """
    åˆ†ææ€§èƒ½è¶‹åŠ¿
    """
    # è·å–è®¾å¤‡ä¿¡æ¯
    device_result = db.execute(select(Device).where(Device.id == device_id))
    device = device_result.scalar_one_or_none()
    if not device:
        raise HTTPException(status_code=404, detail="Device not found")

    # è·å–å†å²æ€§èƒ½æŒ‡æ ‡
    since = datetime.utcnow() - timedelta(hours=hours)
    metrics_result = db.execute(
        select(PerformanceMetric)
        .where(PerformanceMetric.device_id == device_id)
        .where(PerformanceMetric.timestamp >= since)
        .order_by(PerformanceMetric.timestamp.asc())
    )
    metrics = metrics_result.scalars().all()

    metrics_history = []
    for m in metrics:
        metrics_history.append(
            {
                "timestamp": m.timestamp.isoformat() if m.timestamp else None,
                "cpu_percent": m.cpu_percent,
                "gpu_percent": m.gpu_percent,
                "memory_percent": m.memory_percent,
            }
        )

    # è·å–å†å²åŸºå‡†æµ‹è¯•
    benchmarks_result = db.execute(
        select(SoftwareBenchmark)
        .where(SoftwareBenchmark.device_id == device_id)
        .where(SoftwareBenchmark.timestamp >= since)
        .order_by(SoftwareBenchmark.timestamp.desc())
    )
    benchmarks = benchmarks_result.scalars().all()

    benchmarks_data = []
    for b in benchmarks:
        benchmarks_data.append(
            {
                "id": b.id,
                "timestamp": b.timestamp.isoformat() if b.timestamp else None,
                "software_code": b.software_code,
                "benchmark_type": b.benchmark_type,
                "score": b.score,
            }
        )

    if not metrics_history and not benchmarks_data:
        raise HTTPException(
            status_code=404,
            detail="No historical data found for the specified time range",
        )

    # è°ƒç”¨ AI åˆ†ææœåŠ¡
    analysis_service = AIAnalysisService()
    result = analysis_service.analyze_performance_trend(
        device_id, metrics_history, benchmarks_data
    )

    # ä¿å­˜åˆ†ææŠ¥å‘Š
    if result.get("status") == "completed":
        report = AIAnalysisReport(
            device_id=device_id,
            analysis_type="performance_trend",
            title=f"æ€§èƒ½è¶‹åŠ¿åˆ†æ - {device.device_name}",
            summary=result.get("trend_summary", ""),
            details=json.dumps(
                {
                    "trend_data": result.get("trend_data"),
                    "benchmark_trend": result.get("benchmark_trend"),
                },
                ensure_ascii=False,
            ),
            conclusions=result.get("trend_summary", ""),
            related_metrics=json.dumps(
                [
                    m.get("timestamp")
                    for m in metrics_history[:: max(1, len(metrics_history) // 100)]
                ]
            ),
            related_benchmarks=json.dumps([b.get("id") for b in benchmarks_data]),
            status="completed",
            model_used=result.get("model"),
        )
        db.add(report)
        db.commit()
        db.refresh(report)

        return {
            "report_id": report.id,
            "status": result.get("status"),
            "summary": result.get("trend_summary"),
            "conclusions": result.get("trend_summary"),
            "recommendations": "",
            "details": result.get("trend_data"),
        }

    raise HTTPException(
        status_code=500, detail=result.get("message", "Analysis failed")
    )


@router.get("/reports", response_model=dict)
def get_analysis_reports(
    device_id: Optional[str] = Query(None),
    analysis_type: Optional[str] = Query(None),
    limit: int = Query(20, ge=1, le=100),
    offset: int = Query(0, ge=0),
    db: Session = Depends(get_db_sync),
):
    """è·å–åˆ†ææŠ¥å‘Šåˆ—è¡¨"""
    query = select(AIAnalysisReport)

    if device_id:
        query = query.where(AIAnalysisReport.device_id == device_id)
    if analysis_type:
        query = query.where(AIAnalysisReport.analysis_type == analysis_type)

    # è·å–æ€»æ•°
    from sqlalchemy import func

    count_query = select(func.count()).select_from(query.subquery())
    total = db.execute(count_query).scalar()

    # è·å–åˆ†é¡µç»“æœ
    query = (
        query.order_by(AIAnalysisReport.created_at.desc()).offset(offset).limit(limit)
    )
    reports = db.execute(query).scalars().all()

    return {
        "total": total,
        "items": [
            {
                "id": r.id,
                "device_id": r.device_id,
                "analysis_type": r.analysis_type,
                "title": r.title,
                "summary": r.summary,
                "status": r.status,
                "model_used": r.model_used,
                "created_at": r.created_at.isoformat() if r.created_at else None,
            }
            for r in reports
        ],
    }


@router.get("/reports/{report_id}", response_model=dict)
def get_analysis_report(report_id: str, db: Session = Depends(get_db_sync)):
    """è·å–åˆ†ææŠ¥å‘Šè¯¦æƒ…"""
    result = db.execute(
        select(AIAnalysisReport).where(AIAnalysisReport.id == report_id)
    )
    report = result.scalar_one_or_none()

    if not report:
        raise HTTPException(status_code=404, detail="Report not found")

    return {
        "id": report.id,
        "device_id": report.device_id,
        "analysis_type": report.analysis_type,
        "title": report.title,
        "summary": report.summary,
        "details": report.details,
        "conclusions": report.conclusions,
        "recommendations": report.recommendations,
        "status": report.status,
        "related_metrics": report.related_metrics,
        "related_benchmarks": report.related_benchmarks,
        "model_used": report.model_used,
        "analysis_duration_ms": report.analysis_duration_ms,
        "created_at": report.created_at.isoformat() if report.created_at else None,
    }
