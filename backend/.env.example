# Backend Environment Configuration
# Copy this file to .env and update values

# Application
APP_NAME=HardwareBenchmark
DEBUG=false
SECRET_KEY=your-secret-key-change-in-production-min-32-chars

# Database (SQLite - no external database required)
DATABASE_URL_SYNC=sqlite:///./hardware_benchmark.db

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost,http://localhost:5173

# JWT
JWT_SECRET_KEY=your-jwt-secret-key-change-in-production
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=1440  # 24 hours

# ================================================
# LLM Configuration (多 AI 提供商)
# ================================================
# 当前使用的 AI 提供商
# 可选值: siliconflow, minimax, deepseek, zhipu, qwen, openai
LLM_PROVIDER=siliconflow

# API Key (从对应 AI 提供商获取)
# - 硅基流动: https://www.siliconflow.cn
# - MiniMax: https://platform.minimaxi.com
# - DeepSeek: https://platform.deepseek.com
# - 智谱 AI: https://www.bigmodel.cn
LLM_API_KEY=your-api-key-here

# 默认模型 (根据提供商选择)
# 硅基流动: Qwen/Qwen2.5-7B-Instruct, deepseek-ai/DeepSeek-R1-Distill-Qwen-7B
# MiniMax: MiniMax-M2.5-highspeed, MiniMax-M2.5
# DeepSeek: deepseek-chat, deepseek-reasoner
# 智谱: glm-4-flash, glm-4-plus
# 通义千问: qwen-plus, qwen-turbo
LLM_MODEL=Qwen/Qwen2.5-7B-Instruct

# LLM 请求超时时间 (秒)
LLM_TIMEOUT=60
